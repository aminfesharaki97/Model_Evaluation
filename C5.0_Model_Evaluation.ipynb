{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Model Evaluation - use adult_ch6_training and adult_ch6_test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.tools.tools as stattools\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Datasets\n",
    "adult_train = pd.read_csv(\"/Users/datascience/Desktop/ADS 502 Data Sets/Website Data Sets/adult_ch6_training.csv\")\n",
    "adult_test = pd.read_csv(\"/Users/datascience/Desktop/ADS 502 Data Sets/Website Data Sets/adult_ch6_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Using the training dataset, create a C5.0 model (Model1) to predict a customerâ€™s Income using Marital Status and Capital Gains and Losses. Obtain the predicted responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '<=50K', '<=50K', ..., '<=50K', '<=50K', '<=50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = adult_train[['Income']]\n",
    "X = adult_train[['Marital status', 'Cap_Gains_Losses']]\n",
    "\n",
    "# Convert categorical variable into a dummy variable form\n",
    "mar_dummy = pd.get_dummies(X['Marital status'])\n",
    "\n",
    "#Add dummy variables back into X variables\n",
    "X = pd.concat((X[['Cap_Gains_Losses']], mar_dummy), axis = 1) #Column-wise Concatation (axis=1)\n",
    "\n",
    "# Use C5.0 model on training set (criterion = 'entropy')\n",
    "c5 = DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=5).fit(X, y)\n",
    "\n",
    "# Predict Income using C5.0 model\n",
    "C5Pred = c5.predict(X)\n",
    "C5Pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. Evaluate Model 1 using the test data set. Construct a contingency table to compare the actual and predicted values of Income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN:  4627 \n",
      "FP:  47 \n",
      "FN:  1141 \n",
      "TP:  340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4627,   47],\n",
       "       [1141,  340]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = adult_test[['Income']]\n",
    "X_t = adult_test[['Marital status', 'Cap_Gains_Losses']]\n",
    "\n",
    "# Convert categorical variable into a dummy variable form\n",
    "mar_dummy_t = pd.get_dummies(X_t['Marital status'])\n",
    "\n",
    "#Add dummy variables back into X variables\n",
    "X_t = pd.concat((X_t[['Cap_Gains_Losses']], mar_dummy_t), axis = 1) #Column-wise Concatation (axis=1)\n",
    "\n",
    "# CART alogrithn (criterion = gini)\n",
    "c5_t = DecisionTreeClassifier(criterion='entropy', max_leaf_nodes=5).fit(X_t, y_t)\n",
    "\n",
    "\n",
    "# Predict Income using Cart\n",
    "C5Pred_t = c5_t.predict(X_t)\n",
    "\n",
    "# Confusion Matrix / Contigency Table \n",
    "cm = confusion_matrix(y_t, C5Pred_t)\n",
    "\n",
    "\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "TP = cm[1][1]\n",
    "print('TN: ', TN, '\\nFP: ', FP, '\\nFN: ', FN, '\\nTP: ', TP)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. For Model1, recapitulate Table7.4 from the text, calculating all of the model evaluation measures shown in the table. Call this table the Model Evaluation Table. Leave space for Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8069861900893582 \n",
      "Error Rate:  0.19301380991064176 \n",
      "Sensitivity/Recall:  0.22957461174881835 \n",
      "Specificity:  0.9899443731279418 \n",
      "Precision:  0.8785529715762274\n"
     ]
    }
   ],
   "source": [
    "### Evaluation Measures ###\n",
    "TAN = TN + FP\n",
    "TAP = FN + TP\n",
    "TPN = TN + FN\n",
    "TPP =  FP + TP\n",
    "GT = TN + FP + FN + TP\n",
    "\n",
    "# Accuracy\n",
    "Acc = (TN + TP) / (GT)\n",
    "# Error Rate\n",
    "Error = 1 - Acc\n",
    "# Sensitivity / Recall\n",
    "Sens = TP / TAP\n",
    "#Specificity\n",
    "Spec = TN/ TAN\n",
    "# Precision\n",
    "Prec = TP/TPP\n",
    "# F1\n",
    "F1 = 2*[(Prec*Sens)/(Prec+Sens)]\n",
    "# F2\n",
    "F2 = 5*[(Prec*Sens)/(4* Prec +Sens)]\n",
    "\n",
    "print('Accuracy: ', Acc, '\\nError Rate: ', Error, '\\nSensitivity/Recall: ', Sens, '\\nSpecificity: ', Spec, '\\nPrecision: ', Prec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. Clearly and completely interpret each of the Model 1 evaluation measures from the Model Evaluation Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: Accuracy represents an overall measure of the proportion of correct classifications made by the model. Model 1 acquired an 80.6% accuracy of correct classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error: Error rate measures the proportion of incorrect classifications. Model 1 had an error rate of 19.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity/Recall: Sensitivity measyres the ability of the model to classify positivitely. The specificity of the model is 22.29%. This is a poor percentage since only 22% of the actual positive records were classified as positive by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specificity: Specificity measures what proportion of all negative records are captured in the model. The specificity of the model 98.89%. This is a great percentage since the model managed to correctyl classify of the actual negative records as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: The precision of the model is 87.8%. In other words, 87.8% of of records responded positively to the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
